{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcl2SpNpdVru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9331debe-6509-4bf3-d410-078fb6917638"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirement"
      ],
      "metadata": {
        "id": "ZGzusUvjrirC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # For additional installation of libraries not included in the colab main library\n",
        "# !pip install \"library_name\"\n",
        "!pip install torch\n",
        "!pip install barbar \n",
        "# !pip install tensorflow\n",
        "# nicesin97@yonsei.ac.kr"
      ],
      "metadata": {
        "id": "DiZR7OJxrmy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca7f1ff-7575-432f-99cf-f7d611b3d1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting barbar\n",
            "  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/MM'"
      ],
      "metadata": {
        "id": "QbWeuznkt2xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6ede3b-2e4a-4d2e-ebe4-d754c78bfab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import shutil\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn # torch 기반 사용 \n",
        "from barbar import Bar\n",
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "e7TAYwTCLozh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "9T8Qkxy0sr6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configuration for train_interface\n",
        "\n",
        "You can check the essential information,\n",
        "and if you want to change model structure or training method,\n",
        "you have to change this file.\n",
        "\"\"\"\n",
        "#######################################################################\n",
        "#                                 path                                #\n",
        "#######################################################################\n",
        "job_dir = './'  # 'FILE PATH for saving models'\n",
        "chkpt_model = None  # 'FILE PATH (if you have pretrained model..)'\n",
        "chkpt = str(\"EPOCH\")\n",
        "if chkpt_model is not None:\n",
        "    chkpt_path = job_dir + chkpt_model + '/chkpt_' + chkpt + '.pt'\n",
        "\n",
        "#######################################################################\n",
        "#                         possible setting                            #\n",
        "#######################################################################\n",
        "# the list you can do\n",
        "model_list = ['SPK_RECOG_MODEL', 'CRN']\n",
        "loss_list = ['Categorical_CE', 'MSE', 'SDR', 'SI-SNR', 'SI-SDR']\n",
        "\n",
        "# experiment number setting\n",
        "expr_name = 'Spk_Recog'\n",
        "DEVICE = 'cuda'  # if you want to run the code with 'cpu', change 'cpu'\n",
        "#######################################################################\n",
        "#                          Experimental setting                       #\n",
        "#######################################################################\n",
        "current_model = model_list[0]\n",
        "current_loss = loss_list[0]\n",
        "\n",
        "# hyper-parameters\n",
        "max_epochs = 200\n",
        "learning_rate = 0.0005\n",
        "batch = 4   # 4, 8, 16, 32, 64\n",
        "\n",
        "#######################################################################\n",
        "#                         model information                           #\n",
        "#######################################################################\n",
        "fs = 16000\n",
        "fft_len = 512           # 1024 # 2048\n",
        "sam_sec = fft_len / fs\n",
        "frm_samp = fs * (fft_len / fs)\n",
        "\n",
        "rnn_layers = 2\n",
        "rnn_input_size = 512\n",
        "rnn_units = 128\n",
        "#######################################################################\n",
        "#                      setting error check                            #\n",
        "#######################################################################\n",
        "# if the setting is wrong, print error message\n",
        "\n",
        "#######################################################################\n",
        "#                           print setting                             #\n",
        "#######################################################################\n",
        "print('--------------------  C  O  N  F  I  G  ----------------------')\n",
        "print('--------------------------------------------------------------')\n",
        "print('MODEL INFO : {}'.format(current_model))\n",
        "print('LOSS INFO : {}'.format(current_loss))\n",
        "print('\\nBATCH : {}'.format(batch))\n",
        "print('LEARNING RATE : {}'.format(learning_rate))\n",
        "print('--------------------------------------------------------------')\n",
        "print('--------------------------------------------------------------\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bqUaQ-SsrpD",
        "outputId": "82003609-16ae-4a65-b4ee-07c185c77655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------  C  O  N  F  I  G  ----------------------\n",
            "--------------------------------------------------------------\n",
            "MODEL INFO : SPK_RECOG_MODEL\n",
            "LOSS INFO : Categorical_CE\n",
            "\n",
            "BATCH : 4\n",
            "LEARNING RATE : 0.0005\n",
            "--------------------------------------------------------------\n",
            "--------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extract"
      ],
      "metadata": {
        "id": "pkWQs11PlHOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "n_spk = 26 #26개 오디오 파일을\n",
        "\n",
        "# 임의의 오디오를 특정 길이가 되도록 padding 하는 함수\n",
        "def pad_audio(audio):\n",
        "    length = len(audio)\n",
        "    return np.concatenate((audio, np.zeros((max_length-length))))\n",
        "\n",
        "\n",
        "# 가장 긴 길이의 오디오를 찾는다.\n",
        "# for문을 돌려서 모든 데이터의 길이를 length라는 리스트 안에 저장합니다\n",
        "# 화자 22명에 대하여 수행\n",
        "length = []\n",
        "for s in range(0, n_spk, 1): \n",
        "    for n in range(1, 6, 1): #5번 -> 1부터 5까지 for문 돌음 \n",
        "        (x,fs) = librosa.load('./data/speaker_data_wav_16k/'+str(s+1)+'_'+str(n) + '.wav')\n",
        "        length.append(len(x))\n",
        "        print(str(s)+'_'+str(n)+'번째 길이 탐색 완료!')\n",
        "\n",
        "max_length = np.max(length) # length라는 리스트 안에서 가장 긴 오디오의 길이를 리턴합니다\n",
        "print('가장 긴 오디오의 길이는 :', max_length/16000, 'seconds')\n",
        "\n",
        "pickle.dump(max_length, open('./data/max_length', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "p6NsF9UxlJ5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66fb53a-c0bc-4e29-abc7-af029049c363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_1번째 길이 탐색 완료!\n",
            "0_2번째 길이 탐색 완료!\n",
            "0_3번째 길이 탐색 완료!\n",
            "0_4번째 길이 탐색 완료!\n",
            "0_5번째 길이 탐색 완료!\n",
            "1_1번째 길이 탐색 완료!\n",
            "1_2번째 길이 탐색 완료!\n",
            "1_3번째 길이 탐색 완료!\n",
            "1_4번째 길이 탐색 완료!\n",
            "1_5번째 길이 탐색 완료!\n",
            "2_1번째 길이 탐색 완료!\n",
            "2_2번째 길이 탐색 완료!\n",
            "2_3번째 길이 탐색 완료!\n",
            "2_4번째 길이 탐색 완료!\n",
            "2_5번째 길이 탐색 완료!\n",
            "3_1번째 길이 탐색 완료!\n",
            "3_2번째 길이 탐색 완료!\n",
            "3_3번째 길이 탐색 완료!\n",
            "3_4번째 길이 탐색 완료!\n",
            "3_5번째 길이 탐색 완료!\n",
            "4_1번째 길이 탐색 완료!\n",
            "4_2번째 길이 탐색 완료!\n",
            "4_3번째 길이 탐색 완료!\n",
            "4_4번째 길이 탐색 완료!\n",
            "4_5번째 길이 탐색 완료!\n",
            "5_1번째 길이 탐색 완료!\n",
            "5_2번째 길이 탐색 완료!\n",
            "5_3번째 길이 탐색 완료!\n",
            "5_4번째 길이 탐색 완료!\n",
            "5_5번째 길이 탐색 완료!\n",
            "6_1번째 길이 탐색 완료!\n",
            "6_2번째 길이 탐색 완료!\n",
            "6_3번째 길이 탐색 완료!\n",
            "6_4번째 길이 탐색 완료!\n",
            "6_5번째 길이 탐색 완료!\n",
            "7_1번째 길이 탐색 완료!\n",
            "7_2번째 길이 탐색 완료!\n",
            "7_3번째 길이 탐색 완료!\n",
            "7_4번째 길이 탐색 완료!\n",
            "7_5번째 길이 탐색 완료!\n",
            "8_1번째 길이 탐색 완료!\n",
            "8_2번째 길이 탐색 완료!\n",
            "8_3번째 길이 탐색 완료!\n",
            "8_4번째 길이 탐색 완료!\n",
            "8_5번째 길이 탐색 완료!\n",
            "9_1번째 길이 탐색 완료!\n",
            "9_2번째 길이 탐색 완료!\n",
            "9_3번째 길이 탐색 완료!\n",
            "9_4번째 길이 탐색 완료!\n",
            "9_5번째 길이 탐색 완료!\n",
            "10_1번째 길이 탐색 완료!\n",
            "10_2번째 길이 탐색 완료!\n",
            "10_3번째 길이 탐색 완료!\n",
            "10_4번째 길이 탐색 완료!\n",
            "10_5번째 길이 탐색 완료!\n",
            "11_1번째 길이 탐색 완료!\n",
            "11_2번째 길이 탐색 완료!\n",
            "11_3번째 길이 탐색 완료!\n",
            "11_4번째 길이 탐색 완료!\n",
            "11_5번째 길이 탐색 완료!\n",
            "12_1번째 길이 탐색 완료!\n",
            "12_2번째 길이 탐색 완료!\n",
            "12_3번째 길이 탐색 완료!\n",
            "12_4번째 길이 탐색 완료!\n",
            "12_5번째 길이 탐색 완료!\n",
            "13_1번째 길이 탐색 완료!\n",
            "13_2번째 길이 탐색 완료!\n",
            "13_3번째 길이 탐색 완료!\n",
            "13_4번째 길이 탐색 완료!\n",
            "13_5번째 길이 탐색 완료!\n",
            "14_1번째 길이 탐색 완료!\n",
            "14_2번째 길이 탐색 완료!\n",
            "14_3번째 길이 탐색 완료!\n",
            "14_4번째 길이 탐색 완료!\n",
            "14_5번째 길이 탐색 완료!\n",
            "15_1번째 길이 탐색 완료!\n",
            "15_2번째 길이 탐색 완료!\n",
            "15_3번째 길이 탐색 완료!\n",
            "15_4번째 길이 탐색 완료!\n",
            "15_5번째 길이 탐색 완료!\n",
            "16_1번째 길이 탐색 완료!\n",
            "16_2번째 길이 탐색 완료!\n",
            "16_3번째 길이 탐색 완료!\n",
            "16_4번째 길이 탐색 완료!\n",
            "16_5번째 길이 탐색 완료!\n",
            "17_1번째 길이 탐색 완료!\n",
            "17_2번째 길이 탐색 완료!\n",
            "17_3번째 길이 탐색 완료!\n",
            "17_4번째 길이 탐색 완료!\n",
            "17_5번째 길이 탐색 완료!\n",
            "18_1번째 길이 탐색 완료!\n",
            "18_2번째 길이 탐색 완료!\n",
            "18_3번째 길이 탐색 완료!\n",
            "18_4번째 길이 탐색 완료!\n",
            "18_5번째 길이 탐색 완료!\n",
            "19_1번째 길이 탐색 완료!\n",
            "19_2번째 길이 탐색 완료!\n",
            "19_3번째 길이 탐색 완료!\n",
            "19_4번째 길이 탐색 완료!\n",
            "19_5번째 길이 탐색 완료!\n",
            "20_1번째 길이 탐색 완료!\n",
            "20_2번째 길이 탐색 완료!\n",
            "20_3번째 길이 탐색 완료!\n",
            "20_4번째 길이 탐색 완료!\n",
            "20_5번째 길이 탐색 완료!\n",
            "21_1번째 길이 탐색 완료!\n",
            "21_2번째 길이 탐색 완료!\n",
            "21_3번째 길이 탐색 완료!\n",
            "21_4번째 길이 탐색 완료!\n",
            "21_5번째 길이 탐색 완료!\n",
            "22_1번째 길이 탐색 완료!\n",
            "22_2번째 길이 탐색 완료!\n",
            "22_3번째 길이 탐색 완료!\n",
            "22_4번째 길이 탐색 완료!\n",
            "22_5번째 길이 탐색 완료!\n",
            "23_1번째 길이 탐색 완료!\n",
            "23_2번째 길이 탐색 완료!\n",
            "23_3번째 길이 탐색 완료!\n",
            "23_4번째 길이 탐색 완료!\n",
            "23_5번째 길이 탐색 완료!\n",
            "24_1번째 길이 탐색 완료!\n",
            "24_2번째 길이 탐색 완료!\n",
            "24_3번째 길이 탐색 완료!\n",
            "24_4번째 길이 탐색 완료!\n",
            "24_5번째 길이 탐색 완료!\n",
            "25_1번째 길이 탐색 완료!\n",
            "25_2번째 길이 탐색 완료!\n",
            "25_3번째 길이 탐색 완료!\n",
            "25_4번째 길이 탐색 완료!\n",
            "25_5번째 길이 탐색 완료!\n",
            "가장 긴 오디오의 길이는 : 40.1895 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'test'      # train / devel / test 이 순으로 \n",
        "if mode == 'train':\n",
        "    start_idx = 1\n",
        "    end_idx = 5\n",
        "elif mode == 'devel':\n",
        "    start_idx = 5\n",
        "    end_idx = 6\n",
        "\n",
        "# 각 speaker들의 1~4번 음원에 대하여 train dataset으로 사용.\n",
        "# train_mfcc_features / train_labels로 저장\n",
        "print('Feature extraction for training data...')\n",
        "data_train = []\n",
        "refer_train = []\n",
        "for s in range(0, n_spk, 1):\n",
        "    for n in range(start_idx, end_idx, 1):\n",
        "        (x, fs) = librosa.load('./data/speaker_data_wav_16k/' + str(s+1) + '_' + str(n) + '.wav')\n",
        "        x = pad_audio(x)\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=fs, n_mfcc=13)\n",
        "        mfccs = mfcc - np.reshape(np.mean(mfcc, 1), (13, 1))  # Remove DC components # 13 x frame_size\n",
        "        mfccs = np.transpose(mfccs)\n",
        "        # labels = np.zeros((mfccs.shape[0], 22))\n",
        "        # labels[:, s - 1] = 1\n",
        "        labels = np.ones((1,))*s           # [1, 1]\n",
        "        data_train.append(np.float16(mfccs))\n",
        "        refer_train.append(np.float16(labels))      # [Batch, 1]\n",
        "        print(str(s) + '_' + str(n) + '번째 완료!')\n",
        "\n",
        "pickle.dump(np.array(data_train), open('./data/mfcc_features_' + str(mode), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
        "pickle.dump(np.array(refer_train), open('./data/labels_' + str(mode), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ae5pWqbylSGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73138cfc-d160-408b-a4e0-13001f70019f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction for training data...\n",
            "0_5번째 완료!\n",
            "1_5번째 완료!\n",
            "2_5번째 완료!\n",
            "3_5번째 완료!\n",
            "4_5번째 완료!\n",
            "5_5번째 완료!\n",
            "6_5번째 완료!\n",
            "7_5번째 완료!\n",
            "8_5번째 완료!\n",
            "9_5번째 완료!\n",
            "10_5번째 완료!\n",
            "11_5번째 완료!\n",
            "12_5번째 완료!\n",
            "13_5번째 완료!\n",
            "14_5번째 완료!\n",
            "15_5번째 완료!\n",
            "16_5번째 완료!\n",
            "17_5번째 완료!\n",
            "18_5번째 완료!\n",
            "19_5번째 완료!\n",
            "20_5번째 완료!\n",
            "21_5번째 완료!\n",
            "22_5번째 완료!\n",
            "23_5번째 완료!\n",
            "24_5번째 완료!\n",
            "25_5번째 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIZVwIZshjAe"
      },
      "source": [
        "# 훈련 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tResuhrMdRS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5010c43-6891-47c6-bc0d-2ef24aeeaa65"
      },
      "source": [
        "# Load data (Training data & Validation data)\n",
        "print('Load data...')\n",
        "X_train = pickle.load(open('./data/mfcc_features_train', 'rb'))\n",
        "Y_train = pickle.load(open('./data/labels_train', 'rb'))\n",
        "\n",
        "X_valid = pickle.load(open('./data/mfcc_features_devel', 'rb'))\n",
        "Y_valid = pickle.load(open('./data/labels_devel', 'rb'))\n",
        "\n",
        "\n",
        "# Validation용 데이터 만들기 (training set의 20%를 validation set으로 설정)\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load data...\n",
            "(104, 1256, 13)\n",
            "(26, 1256, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "Wh-ojxMEu1Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clip padding\n",
        "max_length = pickle.load(open('./data/max_length', 'rb'))\n",
        "\n",
        "# Reshape\n",
        "X_train = np.transpose(X_train, (0, 2, 1))\n",
        "X_valid = np.transpose(X_valid, (0, 2, 1))\n",
        "\n",
        "\n",
        "def create_dataloader(mode):\n",
        "    if mode == 'train':\n",
        "        return DataLoader(\n",
        "            dataset=Wave_Dataset(mode),\n",
        "            batch_size=batch,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "            drop_last=True,\n",
        "            sampler=None\n",
        "        )\n",
        "    elif mode == 'devel':\n",
        "        return DataLoader(\n",
        "            dataset=Wave_Dataset(mode),\n",
        "            batch_size=batch, shuffle=False, num_workers=0\n",
        "        )\n",
        "\n",
        "\n",
        "class Wave_Dataset(Dataset):\n",
        "    def __init__(self, mode):\n",
        "        # load data\n",
        "        if mode == 'train':\n",
        "            print('<Training dataset>')\n",
        "            print('Load the data...')\n",
        "            self.input = X_train\n",
        "            self.target = Y_train\n",
        "        elif mode == 'devel':\n",
        "            print('<Validation dataset>')\n",
        "            print('Load the data...')\n",
        "            self.input = X_valid\n",
        "            self.target = Y_valid\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "            inputs = self.input[idx]\n",
        "            targets = self.target[idx]\n",
        "\n",
        "            # transform to torch from numpy\n",
        "            inputs = torch.from_numpy(inputs)\n",
        "            targets = torch.from_numpy(targets)\n",
        "            return inputs, targets[0]"
      ],
      "metadata": {
        "id": "DyN7KlD8uwEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3jeaGrZhnRO"
      },
      "source": [
        "#모델 설계\n",
        "\n",
        "학습 데이터는 모두 준비되었고, 이제 학습을 위한 모델을 설계해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkYQpRgOhiQc"
      },
      "source": [
        "class SPK_RECOG_MODEL( nn.Module ):\n",
        "    def __init__(self):\n",
        "        super(SPK_RECOG_MODEL, self).__init__()\n",
        "\n",
        "        self.conv_1st_layer = nn.Conv1d(13, 26, kernel_size=3, padding=1, stride=2, dilation=1)  # (B, 13, 1229) --> (B, 26, 628)\n",
        "        self.normalized_1st_layer = nn.BatchNorm1d(26) #네트워크 연산 결과가 원하는 방향의 분포대로 흘러가기 위해 넣었습니다. 즉, activation function 인 PReLU이 적용되어 분포가 달라지기 전에 적용해야된다. \n",
        "        self.act_1st_layer = nn.PReLU() #활성화 함수로 제일 적합        \n",
        "        self.pool_1st_layer = nn.MaxPool1d(kernel_size = 2, stride = 2) # (B, 26, 314) 정규화 기법 이후에 우리가 원하는 값들만 빠르게 뽑아내기 때문에 시간 효율과 정확도 면에서 좋아졌다. \n",
        "        \n",
        "        self.conv_2nd_layer = nn.Conv1d(26, 78, kernel_size=3, padding=1, stride=2, dilation=1)  # (B, 26, 314) --> (B, 78, 157) \n",
        "        self.normalized_2nd_layer = nn.BatchNorm1d(78) #네트워크 연산 결과가 원하는 방향의 분포대로 흘러가기 위해 넣었습니다.\n",
        "        self.act_2nd_layer = nn.PReLU() #활성화 함수로 제일 적합\n",
        "        self.pool_2nd_layer = nn.MaxPool1d(kernel_size = 2) # (B, 78, 157) --> (B, 78, 78) 입력벡터에서 특정 구간마다 값을 골라 벡터를 구성한 후 반환합니다(2개 뽑아내서 제일 큰 1개 반환). 정규화 기법 이후에 우리가 원하는 값들만 빠르게 뽑아내기 때문에 시간 효율과 정확도 면에서 좋아졌다. \n",
        "\n",
        "        self.conv_3rd_layer = nn.Conv1d(78, 52, kernel_size=3, padding=2, stride=2, dilation=1)  # (B, 78, 78) --> (B, 52, 40) \n",
        "        self.normalized_3nd_layer = nn.BatchNorm1d(52)#네트워크 연산 결과가 원하는 방향의 분포대로 흘러가기 위해 넣었습니다.\n",
        "        self.act_3rd_layer = nn.PReLU()#활성화 함수로 제일 적합 \n",
        "        self.dropout = nn.Dropout(0.5) #과적합을 방지하기 위해서 학습 시에 지정된 비율만큼 임의의 입력 뉴런(1차원)을 제외시킵니다. 위에는 안 넣은 이유는 안 그래도 데이터 표본도 적은데 처음부터 이렇게 하면 데이터 수가 부족해서 훈련을 못한 데이터가 생길 수도 있으므로\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2 , stride = 2) # (B, 52, 40) --> (B, 52, 20)  \n",
        "\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(1040, 512) #3140 ,512\n",
        "        self.act_fc1 = nn.PReLU()\n",
        "        \n",
        "        self.fc2 = nn.Linear(512, 256) #1024 256\n",
        "        self.act_fc2 = nn.PReLU()\n",
        "        \n",
        "        self.fc3 = nn.Linear(256, 26)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # CNN layers\n",
        "        x1 = self.conv_1st_layer(x)\n",
        "        x1 = self.normalized_1st_layer(x1) \n",
        "        x1 = self.act_1st_layer(x1)             \n",
        "        x1 = self.pool_1st_layer(x1) \n",
        "        \n",
        "        x2 = self.conv_2nd_layer(x1)\n",
        "        x2 = self.normalized_2nd_layer(x2) \n",
        "        x2 = self.act_2nd_layer(x2)        \n",
        "        x2 = self.pool_2nd_layer(x2) \n",
        "        \n",
        "        x3 = self.conv_3rd_layer(x2)\n",
        "        x3 = self.normalized_3nd_layer(x3)       \n",
        "        x3 = self.act_3rd_layer(x3)\n",
        "        x3 = self.dropout(x3)\n",
        "        x3 = self.maxpool(x3)         \n",
        "\n",
        "        # Flattening\n",
        "        x_flat = self.flatten(x3)\n",
        "\n",
        "        # FCN layers\n",
        "        x4 = self.fc1(x_flat)\n",
        "        x4 = self.act_fc1(x4)\n",
        "\n",
        "        x5 = self.fc2(x4)\n",
        "        x5 = self.act_fc2(x5)\n",
        "\n",
        "        x6 = self.fc3(x5)\n",
        "\n",
        "        return x6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "T_U4-WNREqx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "#                             For train                               #\n",
        "#######################################################################\n",
        "def model_train(model, optimizer, train_loader, DEVICE, criterion):\n",
        "    # initialization\n",
        "    train_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    for inputs, labels in Bar( train_loader ):\n",
        "        batch_num += 1\n",
        "\n",
        "        # to cuda\n",
        "        inputs = inputs.float().to(DEVICE)\n",
        "        labels = labels.float().to(DEVICE)  # labels.shape [B]\n",
        "\n",
        "        est = model(inputs)  # est.shape [B, 26]\n",
        "        loss = F.cross_entropy(est, labels.long())\n",
        "\n",
        "        # # if you want to check the scale of the loss\n",
        "        # print('loss: {:.4}'.format(loss))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "    train_loss /= batch_num\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "#                           For validation                            #\n",
        "#######################################################################\n",
        "def model_validate(model, validation_loader, dir_to_save, epoch, DEVICE, criterion):\n",
        "    # initialization\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in Bar( validation_loader ):\n",
        "            batch_num += 1\n",
        "\n",
        "            # to cuda\n",
        "            inputs = inputs.float().to(DEVICE)\n",
        "            labels = labels.float().to(DEVICE)\n",
        "\n",
        "            est = model(inputs)                         # est.shape = [Batch, Num_of_Spk] (batch, 22)\n",
        "            loss = F.cross_entropy(est, labels.long())\n",
        "\n",
        "            # Calculate Accuracy\n",
        "            ans, est_idx = torch.max(est, 1)\n",
        "            correct += est_idx.eq(labels).sum().item()  #\n",
        "\n",
        "            validation_loss += loss\n",
        "\n",
        "        validation_loss /= batch_num\n",
        "        valid_acc = 100. * correct / len(validation_loader.dataset)\n",
        "\n",
        "        return validation_loss, valid_acc\n"
      ],
      "metadata": {
        "id": "zNXm6QT0EsYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Interface\n",
        "\n",
        "모델 훈련\n",
        "\n",
        "이제, 학습을 시작합니다.\n",
        "\n",
        "Epoch은 전체 데이터에 대한 반복 학습 횟수입니다.\n",
        "\n",
        "학습 도중 각 단계마다 오차(loss)와 정확도(acc)가 출력됩니다.\n",
        "\n",
        "학습이 진행되는 동안 이 둘이 어떻게 변하는지 확인합니다.\n",
        "\n",
        "매 Epoch마다 체크 포인트를 발동하여 weights정보를 기록합니다. 가장 validation accuracy가 높았을 때의 weights를 저장하기 위합니다.\n"
      ],
      "metadata": {
        "id": "p0dgiKMvG9Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                        Helper function definition                           #\n",
        "###############################################################################\n",
        "# Write training related parameters into the log file.\n",
        "def write_status_to_log_file(fp, total_parameters):\n",
        "    fp.write('%d-%d-%d %d:%d:%d\\n' %\n",
        "             (time.localtime().tm_year, time.localtime().tm_mon,\n",
        "              time.localtime().tm_mday, time.localtime().tm_hour,\n",
        "              time.localtime().tm_min, time.localtime().tm_sec))\n",
        "    fp.write('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
        "             (total_parameters,\n",
        "              total_parameters / 1000000.0,\n",
        "              total_parameters * 4.0 / 1000000.0))\n",
        "\n",
        "\n",
        "# Calculate the size of total network.\n",
        "def calculate_total_params(our_model):\n",
        "    total_parameters = 0\n",
        "    for variable in our_model.parameters():\n",
        "        shape = variable.size()\n",
        "        variable_parameters = 1\n",
        "        for dim in shape:\n",
        "            variable_parameters *= dim\n",
        "        total_parameters += variable_parameters\n",
        "\n",
        "    return total_parameters\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#         Parameter Initialization and Setting for model training             #\n",
        "###############################################################################\n",
        "# Set device\n",
        "DEVICE = torch.device('cuda') # if you want to run the code with 'cpu', change 'cpu'\n",
        "\n",
        "# Set model\n",
        "model = SPK_RECOG_MODEL().to(DEVICE)\n",
        "\n",
        "# Set optimizer and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "total_params = calculate_total_params(model)\n",
        "\n",
        "###############################################################################\n",
        "#                        Confirm model information                            #\n",
        "###############################################################################\n",
        "print('%d-%d-%d %d:%d:%d\\n' %\n",
        "      (time.localtime().tm_year, time.localtime().tm_mon,\n",
        "       time.localtime().tm_mday, time.localtime().tm_hour,\n",
        "       time.localtime().tm_min, time.localtime().tm_sec))\n",
        "print('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
        "      (total_params,\n",
        "       total_params / 1000000.0,\n",
        "       total_params * 4.0 / 1000000.0))\n",
        "\n",
        "###############################################################################\n",
        "#                              Create Dataloader                              #\n",
        "###############################################################################\n",
        "train_loader = create_dataloader(mode='train')\n",
        "validation_loader = create_dataloader(mode='devel')\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(torch.ones(22)).to(DEVICE)\n",
        "# criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "###############################################################################\n",
        "#                        Set a log file to store progress.                    #\n",
        "#               Set a hps file to store hyper-parameters information.         #\n",
        "###############################################################################\n",
        "if chkpt_model is not None:  # Load the checkpoint\n",
        "    print('Resuming from checkpoint: %s' % chkpt_path)\n",
        "\n",
        "    # Set a log file to store progress.\n",
        "    dir_to_save = job_dir + chkpt_model\n",
        "\n",
        "    checkpoint = torch.load(chkpt_path)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    epoch_start_idx = checkpoint['epoch'] + 1\n",
        "    acc_vali_total = np.load(str(dir_to_save + '/acc_vali_total.npy'))\n",
        "else:  # First learning\n",
        "    print('Starting new training run...')\n",
        "    epoch_start_idx = 1\n",
        "    acc_vali_total = np.zeros(max_epochs)\n",
        "\n",
        "    # Set a log file to store progress.\n",
        "    dir_to_save = job_dir + expr_name + '_%d.%d' % (time.localtime().tm_mon,\n",
        "                                                           time.localtime().tm_mday) + '_%s' % current_model + '_%s' % current_loss\n",
        "\n",
        "# make the file directory\n",
        "if not os.path.exists(dir_to_save):\n",
        "    os.mkdir(dir_to_save)\n",
        "\n",
        "# logging\n",
        "log_fname = str(dir_to_save + '/log.txt')\n",
        "fp = open(log_fname, 'w')\n",
        "write_status_to_log_file(fp, total_params)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "#                             Main program start !!                           #\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "###############################################################################\n",
        "#                                    Train                                    #\n",
        "###############################################################################\n",
        "acc_valid_total = np.zeros(max_epochs)\n",
        "\n",
        "for epoch in range(epoch_start_idx, max_epochs):\n",
        "        start_time = time.time()\n",
        "        # Training\n",
        "        train_loss = model_train(model, optimizer, train_loader, DEVICE, criterion)\n",
        "\n",
        "        # save checkpoint file to resume training\n",
        "        save_path = str(dir_to_save + '/' + ('chkpt_%d.pt' % epoch))\n",
        "\n",
        "        torch.save({\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch\n",
        "        }, save_path)\n",
        "\n",
        "        # Validation\n",
        "        valid_loss, valid_acc = \\\n",
        "        model_validate(model, validation_loader, dir_to_save, epoch, DEVICE, criterion)\n",
        "\n",
        "        print('Epoch [{}] | T {:.6f} | V {:.4} V_ACC {:.2f} takes {:.2f} seconds\\n'\n",
        "                  .format(epoch, train_loss, valid_loss, valid_acc, time.time() - start_time))\n",
        "        # log file save\n",
        "        fp.write('Epoch [{}] | T {:.6f} | V {:.4} V_ACC {:.2f} takes {:.2f} seconds\\n'\n",
        "                     .format(epoch, train_loss, valid_loss, valid_acc, time.time() - start_time))\n",
        "\n",
        "        acc_valid_total[epoch - 1] = valid_acc\n",
        "        np.save(str(dir_to_save + '/acc_valid_total.npy'), acc_valid_total)\n",
        "\n",
        "\n",
        "fp.close()\n",
        "print('Training has been finished.')\n",
        "\n",
        "# Copy optimum model that has minimum MSE.\n",
        "print('Save optimum models...')\n",
        "max_index = np.argmax(acc_valid_total)\n",
        "print('Maximum Accuracy is at ' + str(max_index + 1) + '.')\n",
        "src_file = str(dir_to_save + '/' + ('chkpt_%d.pt' % (max_index + 1)))\n",
        "tgt_file = str(dir_to_save + '/chkpt_opt.pt')\n",
        "shutil.copy(src_file, tgt_file)"
      ],
      "metadata": {
        "id": "RRpgtUvjG_4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45d8ef84-c008-4a8a-82f0-804f0806173f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-6-30 9:35:0\n",
            "\n",
            "total params   : 690741 (0.69 M, 2.76 MBytes)\n",
            "\n",
            "<Training dataset>\n",
            "Load the data...\n",
            "<Validation dataset>\n",
            "Load the data...\n",
            "Starting new training run...\n",
            "104/104: [==============================>.] - ETA 0.7s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [1] | T 3.340993 | V 3.101 V_ACC 23.08 takes 0.94 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [2] | T 2.696152 | V 2.435 V_ACC 34.62 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [3] | T 1.665870 | V 1.699 V_ACC 50.00 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [4] | T 0.724775 | V 1.144 V_ACC 76.92 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [5] | T 0.214705 | V 0.9573 V_ACC 76.92 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [6] | T 0.078451 | V 0.6581 V_ACC 84.62 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [7] | T 0.035082 | V 0.831 V_ACC 88.46 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [8] | T 0.029600 | V 0.8507 V_ACC 84.62 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [9] | T 0.049692 | V 0.649 V_ACC 84.62 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [10] | T 0.024254 | V 0.6668 V_ACC 84.62 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [11] | T 0.008881 | V 0.5799 V_ACC 88.46 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [12] | T 0.005134 | V 0.5376 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [13] | T 0.004210 | V 0.5035 V_ACC 88.46 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [14] | T 0.003716 | V 0.491 V_ACC 88.46 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [15] | T 0.003261 | V 0.4574 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [16] | T 0.002415 | V 0.4725 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [17] | T 0.002198 | V 0.476 V_ACC 88.46 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [18] | T 0.001952 | V 0.4876 V_ACC 88.46 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [19] | T 0.002279 | V 0.4569 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [20] | T 0.002372 | V 0.4487 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [21] | T 0.001891 | V 0.4377 V_ACC 92.31 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [22] | T 0.001543 | V 0.4531 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [23] | T 0.001394 | V 0.456 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [24] | T 0.001475 | V 0.4545 V_ACC 92.31 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [25] | T 0.001249 | V 0.445 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [26] | T 0.001852 | V 0.4501 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [27] | T 0.001129 | V 0.4589 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [28] | T 0.000887 | V 0.4514 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [29] | T 0.001124 | V 0.4186 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [30] | T 0.000795 | V 0.4208 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [31] | T 0.000728 | V 0.4299 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [32] | T 0.000783 | V 0.4159 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [33] | T 0.000643 | V 0.4259 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [34] | T 0.000729 | V 0.4113 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [35] | T 0.000777 | V 0.4182 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [36] | T 0.000590 | V 0.4355 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [37] | T 0.000485 | V 0.4157 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [38] | T 0.000725 | V 0.4233 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [39] | T 0.000608 | V 0.4357 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [40] | T 0.000443 | V 0.4335 V_ACC 96.15 takes 0.32 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [41] | T 0.000423 | V 0.4247 V_ACC 96.15 takes 0.39 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [42] | T 0.000362 | V 0.4157 V_ACC 96.15 takes 0.39 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [43] | T 0.000571 | V 0.392 V_ACC 96.15 takes 0.36 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [44] | T 0.000511 | V 0.4052 V_ACC 92.31 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [45] | T 0.000482 | V 0.4241 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [46] | T 0.000518 | V 0.4311 V_ACC 92.31 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [47] | T 0.000453 | V 0.4288 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [48] | T 0.000318 | V 0.4338 V_ACC 92.31 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [49] | T 0.000416 | V 0.4269 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [50] | T 0.000308 | V 0.4339 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [51] | T 0.000333 | V 0.4069 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [52] | T 0.000274 | V 0.4036 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [53] | T 0.000401 | V 0.4028 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [54] | T 0.000315 | V 0.4052 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [55] | T 0.000235 | V 0.4039 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [56] | T 0.000241 | V 0.3956 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [57] | T 0.000239 | V 0.4078 V_ACC 96.15 takes 0.38 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [58] | T 0.000225 | V 0.4031 V_ACC 96.15 takes 0.38 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [59] | T 0.000231 | V 0.4054 V_ACC 96.15 takes 0.34 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [60] | T 0.000347 | V 0.4116 V_ACC 96.15 takes 0.32 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [61] | T 0.000276 | V 0.3857 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [62] | T 0.000266 | V 0.4038 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [63] | T 0.000234 | V 0.4076 V_ACC 92.31 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [64] | T 0.000240 | V 0.4175 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [65] | T 0.000217 | V 0.4169 V_ACC 92.31 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [66] | T 0.000463 | V 0.3744 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [67] | T 0.000297 | V 0.3775 V_ACC 96.15 takes 0.57 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [68] | T 0.000337 | V 0.3692 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [69] | T 0.000215 | V 0.3848 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [70] | T 0.000187 | V 0.3844 V_ACC 96.15 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [71] | T 0.000172 | V 0.3984 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [72] | T 0.000186 | V 0.4036 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [73] | T 0.000197 | V 0.4192 V_ACC 96.15 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [74] | T 0.000213 | V 0.4107 V_ACC 96.15 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [75] | T 0.000182 | V 0.3914 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [76] | T 0.000160 | V 0.3966 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [77] | T 0.000156 | V 0.3965 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [78] | T 0.000114 | V 0.4129 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [79] | T 0.000137 | V 0.4002 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [80] | T 0.000163 | V 0.4043 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [81] | T 0.000124 | V 0.3973 V_ACC 96.15 takes 0.35 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [82] | T 0.000136 | V 0.4032 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [83] | T 0.000215 | V 0.416 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [84] | T 0.000139 | V 0.4029 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [85] | T 0.000120 | V 0.407 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [86] | T 0.000148 | V 0.3883 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [87] | T 0.000093 | V 0.3939 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [88] | T 0.000095 | V 0.3978 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [89] | T 0.000117 | V 0.3906 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [90] | T 0.000110 | V 0.3859 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [91] | T 0.000086 | V 0.4005 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [92] | T 0.000107 | V 0.4027 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [93] | T 0.000099 | V 0.3857 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [94] | T 0.000120 | V 0.3847 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [95] | T 0.000082 | V 0.3814 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [96] | T 0.000084 | V 0.3872 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [97] | T 0.000079 | V 0.3862 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [98] | T 0.000079 | V 0.387 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [99] | T 0.000072 | V 0.3964 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [100] | T 0.000110 | V 0.3869 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [101] | T 0.000071 | V 0.3858 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [102] | T 0.000095 | V 0.3733 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [103] | T 0.000069 | V 0.373 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [104] | T 0.000074 | V 0.3793 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [105] | T 0.000060 | V 0.3784 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [106] | T 0.000078 | V 0.4017 V_ACC 96.15 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [107] | T 0.000070 | V 0.4057 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [108] | T 0.000117 | V 0.396 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [109] | T 0.000062 | V 0.3887 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [110] | T 0.000065 | V 0.3856 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [111] | T 0.000078 | V 0.3924 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [112] | T 0.000085 | V 0.3756 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [113] | T 0.000076 | V 0.3662 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [114] | T 0.000075 | V 0.369 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [115] | T 0.000078 | V 0.3726 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [116] | T 0.000049 | V 0.3749 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [117] | T 0.000040 | V 0.3676 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [118] | T 0.000096 | V 0.3383 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [119] | T 0.000048 | V 0.3196 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [120] | T 0.000054 | V 0.3308 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [121] | T 0.000075 | V 0.3497 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [122] | T 0.000065 | V 0.3344 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [123] | T 0.000067 | V 0.3526 V_ACC 96.15 takes 0.32 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [124] | T 0.000041 | V 0.3653 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [125] | T 0.000039 | V 0.3599 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [126] | T 0.000049 | V 0.3632 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [127] | T 0.000066 | V 0.3777 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [128] | T 0.000067 | V 0.3926 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [129] | T 0.000045 | V 0.4004 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [130] | T 0.000048 | V 0.402 V_ACC 92.31 takes 0.32 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [131] | T 0.000053 | V 0.4012 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [132] | T 0.000036 | V 0.4099 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [133] | T 0.000033 | V 0.417 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [134] | T 0.000036 | V 0.4017 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [135] | T 0.000047 | V 0.4056 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [136] | T 0.000030 | V 0.3991 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [137] | T 0.000033 | V 0.4009 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [138] | T 0.000048 | V 0.406 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [139] | T 0.000033 | V 0.4009 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [140] | T 0.000023 | V 0.4039 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [141] | T 0.000027 | V 0.4007 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [142] | T 0.000034 | V 0.3954 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [143] | T 0.000038 | V 0.4046 V_ACC 92.31 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [144] | T 0.000034 | V 0.3967 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [145] | T 0.000026 | V 0.3833 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [146] | T 0.000047 | V 0.3948 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [147] | T 0.000030 | V 0.3918 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [148] | T 0.000045 | V 0.3885 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [149] | T 0.000041 | V 0.3965 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [150] | T 0.000041 | V 0.369 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [151] | T 0.000027 | V 0.3782 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [152] | T 0.000033 | V 0.3772 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [153] | T 0.000039 | V 0.3695 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [154] | T 0.000036 | V 0.3504 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [155] | T 0.000033 | V 0.359 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [156] | T 0.000027 | V 0.3684 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [157] | T 0.000038 | V 0.379 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [158] | T 0.000027 | V 0.3753 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [159] | T 0.000021 | V 0.3884 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [160] | T 0.000019 | V 0.3813 V_ACC 96.15 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [161] | T 0.000019 | V 0.402 V_ACC 92.31 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [162] | T 0.000018 | V 0.3858 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [163] | T 0.000025 | V 0.3875 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [164] | T 0.000018 | V 0.3926 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [165] | T 0.000027 | V 0.3803 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [166] | T 0.000035 | V 0.4005 V_ACC 92.31 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [167] | T 0.000019 | V 0.4072 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [168] | T 0.000027 | V 0.4005 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [169] | T 0.000028 | V 0.3919 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [170] | T 0.000020 | V 0.3913 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [171] | T 0.000022 | V 0.3854 V_ACC 96.15 takes 0.31 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [172] | T 0.000021 | V 0.3949 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [173] | T 0.000021 | V 0.3907 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [174] | T 0.000045 | V 0.3792 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [175] | T 0.000021 | V 0.3854 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [176] | T 0.000022 | V 0.381 V_ACC 96.15 takes 0.21 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [177] | T 0.000020 | V 0.3678 V_ACC 96.15 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [178] | T 0.000030 | V 0.3793 V_ACC 96.15 takes 0.26 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [179] | T 0.000039 | V 0.4193 V_ACC 92.31 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [180] | T 0.000023 | V 0.4249 V_ACC 92.31 takes 0.58 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [181] | T 0.000020 | V 0.4224 V_ACC 92.31 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [182] | T 0.000014 | V 0.4245 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [183] | T 0.000018 | V 0.4151 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [184] | T 0.000019 | V 0.4155 V_ACC 92.31 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [185] | T 0.000020 | V 0.4031 V_ACC 92.31 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [186] | T 0.000017 | V 0.3832 V_ACC 96.15 takes 0.27 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [187] | T 0.000018 | V 0.3882 V_ACC 96.15 takes 0.29 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [188] | T 0.000028 | V 0.3899 V_ACC 92.31 takes 0.31 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [189] | T 0.000017 | V 0.375 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [190] | T 0.000022 | V 0.3826 V_ACC 92.31 takes 0.31 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [191] | T 0.000015 | V 0.3943 V_ACC 92.31 takes 0.68 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [192] | T 0.000015 | V 0.3711 V_ACC 96.15 takes 0.39 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [193] | T 0.000015 | V 0.3802 V_ACC 92.31 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [194] | T 0.000015 | V 0.3798 V_ACC 96.15 takes 0.23 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [195] | T 0.000016 | V 0.3714 V_ACC 96.15 takes 0.25 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [196] | T 0.000011 | V 0.3886 V_ACC 92.31 takes 0.28 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [197] | T 0.000012 | V 0.3895 V_ACC 96.15 takes 0.30 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [198] | T 0.000017 | V 0.3982 V_ACC 92.31 takes 0.24 seconds\n",
            "\n",
            "104/104: [==============================>.] - ETA 0.0s\n",
            "26/26: [===========================>....] - ETA 0.0s\n",
            "Epoch [199] | T 0.000018 | V 0.3938 V_ACC 96.15 takes 0.22 seconds\n",
            "\n",
            "Training has been finished.\n",
            "Save optimum models...\n",
            "Maximum Accuracy is at 15.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./Spk_Recog_6.30_SPK_RECOG_MODEL_Categorical_CE/chkpt_opt.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZjeuNTlirZZ"
      },
      "source": [
        "# 모델 평가 및 결과 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhxtDWyuixkA"
      },
      "source": [
        "다음은 훈련 중 loss와 accuracy가 어떻게 변했는지를 그래프로 나타내보겠습니다.\n",
        "\n",
        "학습 과정이 길다면 한 눈에 살펴볼 수 있는 좋은 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQotUfTmitex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0edc6bef-e010-4a0d-9934-6615154e692c"
      },
      "source": [
        "fp = open('./Spk_Recog_6.30_SPK_RECOG_MODEL_Categorical_CE/log.txt', 'r')\n",
        "line = fp.readlines()\n",
        "\n",
        "train_loss = np.zeros((len(line)-2, ))\n",
        "valid_loss = np.zeros((len(line)-2, ))\n",
        "valid_acc = np.zeros((len(line)-2, ))\n",
        "\n",
        "for idx in range(2, len(line)):\n",
        "    train_loss[idx-2] = line[idx].split(' ')[4]\n",
        "    valid_loss[idx-2] = line[idx].split(' ')[7]\n",
        "    valid_acc[idx-2] = line[idx].split(' ')[9]\n",
        "\n",
        "fp.close()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Loss')\n",
        "plt.plot(train_loss, 'b', label='train')\n",
        "plt.plot(valid_loss, 'r', label='valid')\n",
        "# plt.xlim([0, 100]); plt.ylim([0, 5])\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(valid_acc, 'r', label='valid')\n",
        "plt.ylim([0, 100]); # plt.xlim([0, 100])\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAEYCAYAAACgOtfQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwcZbn3/881+0z2PSEJTBCEEAjZINEoJwIqghA8gEFUAnLg+SEIQfR3cENQOI94jhsKaAQUzgmbAWQRBMSEHBDQJIYkECERJjBZJ3tCMslM5nr+uKszncksPZNepnq+79erX91dXV11V/dM97ev+64qc3dERERE8kVBrhsgIiIikk4KNyIiIpJXFG5EREQkryjciIiISF5RuBEREZG8onAjIiIieUXhRkRERPKKwo20m5lVmdmpuW6HiMSPmc01s81mVprrtkj+UrgREZGsMLNK4KOAA2dlcb1F2VqXdA4KN5IWZlZqZj81s9XR5aeJX2Zm1t/MnjSzLWa2ycz+18wKosf+3cxWmdl2M3vTzE7J7ZaISAZdCLwC/BaYnphoZsPN7BEzqzGzjWb2i6THLjWzZdFnxBtmNi6a7mZ2RNJ8vzWzm6LbU8ysOvp8WQv8xsz6RJ9DNVHl6EkzG5b0/L5m9pvo82uzmf0+mr7UzM5Mmq/YzDaY2diMvUpy0BRuJF2+BUwCxgDHAycC344euxaoBgYAg4BvAm5mRwFXAie4ew/gk0BVdpstIll0ITArunzSzAaZWSHwJLASqASGAg8AmNl5wA3R83oSqj0bU1zXYKAvcBhwGeH77jfR/UOBXcAvkub/b6ACGAUMBH4STb8X+ELSfKcDa9z97ym2Q3JApTpJl88DX3H39QBmdiPwK+A7QB0wBDjM3VcA/xvNsxcoBY4xsxp3r8pFw0Uk88zsI4Rg8ZC7bzCzfwIXECo5hwBfd/f6aPYXo+t/A37o7n+L7q9oxyobgO+6++7o/i7g4aT23AzMiW4PAT4F9HP3zdEsL0TX/wN8x8x6uvs24IuEICSdmCo3ki6HEH55JayMpgH8J+FD6Vkze9vMrgOIgs4Mwi+z9Wb2gJkdgojko+nAs+6+Ibp/XzRtOLAyKdgkGw78s4Prq3H32sQdM6sws1+Z2Uoz2wbMA3pHlaPhwKakYLOPu68GXgLOMbPehBA0q4NtkixRuJF0WU34VZZwaDQNd9/u7te6++GEsvJXE2Nr3P0+d0/8onPgluw2W0QyzczKgc8C/2Jma6NxMNcQurDXAYe2MOj3PeADLSx2J6EbKWFwk8e9yf1rgaOAie7eEzgp0bxoPX2j8NKcewhdU+cBL7v7qhbmk05C4UY6qtjMyhIX4H7g22Y2wMz6A9cTyrmY2afN7AgzM2ArsBdoMLOjzOzkaOBxLaFs3JCbzRGRDDqb8H9/DGFc3hhgJKGL+mxgDfADM+sWfaZMjp53J/A1MxtvwRFmlvgRtQi4wMwKzew04F/aaEMPwmfMFjPrC3w38YC7rwGeBm6PBh4Xm9lJSc/9PTAOuJowBkc6OYUb6ainCB8UiUsZMB9YDCwBFgI3RfMeCfwJ2AG8DNzu7nMI421+AGwA1hIG8X0je5sgIlkyHfiNu7/r7msTF8KA3s8BZwJHAO8Sdj6YBuDuvwNuJnRhbSeEjL7RMq+OnreFMObv92204adAOeHz5hXgj00e/yJhfOA/gPWELnOidiTG64wAHmnntksOmHvTyp2IiIgkM7PrgQ+6+xfanFlyTntLiYiItCLqxrqEUN2RGFC3lIjklJndbWbrzWxp0rS+ZvacmS2PrvtE083MbjWzFWa2OHFAN5FMMbNLCQOOn3b3ebluj6SmzXATDe76q5m9ZmavR8cvaTrPRdFRHxdFl3/LTHNFJA/9FjitybTrgOfd/Ujg+eg+hN1wj4wulwF3ZKmN0kW5+6/dvZu7/3+5boukLpXKzW7gZHc/njDC/TQzm9TMfA+6+5jocmdaWykieSv6NbypyeSphN1via7PTpp+rwevEI5TMiQ7LRWRuGhzzI2HEcc7orvF0eWgRyH379/fKysrD3YxItJJLFiwYIO7D0jT4gZFu+dC2JNuUHR7KKGLIKE6mraGJszsMkJ1h27duo0/+uij09Q0EekMWvvMSWlAcXQExwWEXfVuc/dXm5ntnOi4AG8B17j7e01nSP6wOfTQQ5k/f36KmyAinZ2ZrWx7rvZzdzezdv+gcveZwEyACRMmuD5vRPJLa585KQ0odve97j4GGAacaGbHNpnlCaDS3UcDz9FYTm66nJnuPsHdJwwYkK4feCKSh9Ylupui6/XR9FWEQ+UnDIumiYjs0669pdx9C+FEY6c1mb4x6eRkdwLj09M8EemiHicc+I3o+rGk6RdGe01NArYmdV+JiACp7S01IHG+jej8IB8nHMExeZ7kAX1nAcvS2UgRyV9mdj/hyNVHmVm1mV1COHL1x81sOXBqdB/CkbHfJpyI9dfAl3PQZBHp5FIZczMEuCcad1NAOF39k2b2PWC+uz8OXGVmZwH1hL0eLspUg0U6o7q6Oqqrq6mtrW175pgrKytj2LBhFBcXp2V57v65Fh46pZl5HbgiLSsWkbyVyt5Si4GxzUy/Pun2N9A5gaQLq66upkePHlRWVhLOD5qf3J2NGzdSXV3NiBEjct0cEZFm6QjFImlQW1tLv3798jrYAJgZ/fr16xIVKhGJL51bSiRN8j3YJHSV7eyQmhpYvx5GjTr4ZW3bBn/4A9TXp/6coiI480zo3n3/6XV18Nhj4A5Tp8Kbb8Ihh0C/fuHxHTvgySfDfM0ZMwaOO67x/h/+AJuaHnexGYWFcMYZsHYt/PWvqW9HHA0fDlOm7D/trbfCe1FUBM8+G17/1hx1VHitH3sM0vEDomdPOOsseOEFeC/p6Cxjx8KIEfDEEy2/581JvJ+9erU8z7x5sHIlnHoqDEkajuseHjvpJHjxRaiqCvOYwebNUFICL78c2tuzZ7s39QDunpPL+PHjXSRfvPHGG7luQlY1t72EMXg5+0xp7ZK1z5srr3QfMiQ9y/rhD93DV0L7Lj/5yYHLevTRxsdnz3bv29f9K19pfPxnP2t9mSNHNs67dGn72nPzze6TJnVsW+J0KShw37p1/9d91Cj3c891v/zy1JbRu3d4f9LZrueeC21r+n7+/OcdW97NN7f8N7tjh3thYZjvkkv2f+z558P0Z591LyoKty+6yP3CC91HjHD/1a/CtHffTflfpLXPnE5fuXniCfjRj+CRR6Bv31y3RqTz2rJlC/fddx9f/nL7diA6/fTTue++++jdu3eGWtaFrF0La9bA9u3Qo8fBLWvFilBZebW5Y6a2YPx4WL68+WUlvPpqqLokz7diRWjv3/9+4HP/8z/hN7+BhgYoKGhc1u9/D8c2PeRZEx/5SFjP8uVwwQXwve+lvi1x8sc/wpVXhmrE6NFhWkND2O6iItiyJVRkZs9ueRn33APf/z688kq4v2QJlJd3vE3//Cd88pOhYtTQALffDp/4ROP7+eab0K0bvPZa6sv8yEf2/1tqauVK2Ls33G76d/jWW+H62Wcbq5HLl4f5q6pCe4qKQkUxDTp9uFm3LlTU3n9f4UakNVu2bOH2228/INzU19dTVNTyv/pTTz2V6aZ1HVu2hOuVK9v+4m/LO+/A4YfDBz6Q+nNGjAhfFM0tq3fv0K0wZ07jtOTHR4xofl3HHw979oTQNnRo4/MmT4b+/Vtvz+GHhy/pjRtDt1Z7tiVOTjwxXL/zTmO4WbMmvG5VVeELbNy41rd/XHSC+7lzQ6g92L+fQdEZSxLv98SJYf2J9/OVV1p+z1ty+OH7/900lXjsAx848O8w8djcueH6iCPCPHv3hprQvHlw6KHhbzQNOv2A4tLScL17d+vziXR11113Hf/85z8ZM2YMJ5xwAh/96Ec566yzOOaYYwA4++yzGT9+PKNGjWLmzJn7nldZWcmGDRuoqqpi5MiRXHrppYwaNYpPfOIT7Nq1K1ebE0+JcNNcwGivqipo7/n3Wgo3iWVVVsLChWHaypXhS6WtdSWmJ5ZbVRV+8SfG67SmsrKxGpTPe9c1fY2Sb2/dCm+/3fZ7mXh84cL2v+/N6d49hM/E+514/Q9mPZWVrf9tJx772Megunr/8TyJxxLt+djHYPXqUO3saHta0ekrNwo3EjczZsCiReld5pgx8NOftj7PD37wA5YuXcqiRYuYO3cuZ5xxBkuXLt23y/bdd99N37592bVrFyeccALnnHMO/Zp8QS1fvpz777+fX//613z2s5/l4Ycf5gtf+EJ6NyafJcJNa79uU9HQEMLHZz7TvudVVsIzz4TQkjzwu6oqDFYtLIQFC8K02tpQGh80KDx+ygGHFQoSX4pVVaFaU1UVpqUysHzEiLAtibblq/79Q+BrLtxAeA3aCneJ1yeVeVM1YgRs2BAG6Ca6nRPL7sh6RoyABx8M3UrNVYOrqqCsDCZNgjvvDAEn+e8nsd6SEvjQh+DXv258bjq3G1VuRPLWiSeeuN+xaG699VaOP/54Jk2axHvvvcfyZsZmjBgxgjFjxgAwfvx4qtJRgehK0lW5Wbs2dB105Jf1zp1hr60E9/0rN8mqqsL4mx07Wl7XYYc1zpu4TrVdyfPlc7gxO7Cq0TTgtrX9vXs3BpB0vVaJ5VRWNobRxPvZkfVUVoZupFUtnM6tqiosP/G5k/waJL82hx0Wurhaam8aqHIjkmZtVViypVu3bvtuz507lz/96U+8/PLLVFRUMGXKlGaPVVOa+IcDCgsL1S3VHu7pCzeJ53fkyyfx/IEDw+0NG0LgqaxsHM9QURGmVVVB4kjTLa2rvLyxupNY9kc/2r72lJc3tidfNQ03VVWNr3Pi8VSWsWhRZsJNQuL9XLfu4P6+kkNSQtMQnXg9du4Mh0hIvB5Ng3by9DRR5UYkT/To0YPt27c3+9jWrVvp06cPFRUV/OMf/+CVxB4Zkj7vv9+4F0iuwk3TLoCmy0osb/LkxsdSWVfii3vLljCGpL2Vm+TKQb5qLtwcd1zjXnPNhYHmlpF8nY42wYHdPR1dT3Nji5Ilws3w4WHPusR8K1eG68TfXWVlGJxeWBjC9QkndKw9rVDlRiRP9OvXj8mTJ3PsscdSXl7OoMTeEsBpp53GL3/5S0aOHMlRRx3FpEmTctjSPPPKK3DkkZCocpWW7v/h//jjYc+Z9nj22XCdyhdissT8s2eHA6NB466+yZWbUaPCQN9nnmkcINZWuHnhhcayZKpfQsOHN3bZ5LvKyhD+fv7zMKbk9dfDQf0SVYtUduvOVLhpurzKynBIgPauJ/F+PvrogQcZrK8PVcLKyhBYhg2D558PIeYf0bm2p0yB554L8xQVheUVFYUuqhdeULgRkebdd999zU4vLS3l6aefbvaxxLia/v37s3Tp0n3Tv/a1r6W9fXmnvj58YM+YAYmB18cdB/PnhyMMb9sWjgjcEUcfHcr17dGzZ9jF9ne/C5fk6YcfHn5N9+8fdl1etiyEGwi/7Fs7ztH48WEg6Y03hoCU2N25LaWl4Wi4iV2l89nY6BSMV13VOG3cuLDX0rp1qS1j4sTw/qRrYO3o0WGAb6Iykrye+fOhT5/2La+0NOyi/thj4dKcxOswblw4FtJf/hLul5fDv/4r/Md/NP49TJwY/p4mTgyhJ/mIxgdJ4UZEpKPeey98OK1Y0TjeZsyY8MWxcmVj9eTBB1Mfp5LQ3i+ehCVLGteb0KNH4ykZ1q0Lv77PPTf80obWgw3A174GF14Y9mipqGj98PtN/e1v+d8lBWFvs40bG7+sCgoaxxkldrlvy7Rp8NnPhuemw7BhYbB402PHzJgBV1/dsfflr3898O8roaSk8RABv/vd/gPbu3cPf4dbtza2J/FjzAwuvTR9243CjYhIxyUPsk0ON4lpiS+BsWPT+qu0VWVlra8r8QVSXJx6m8waDwrXXmn8wur0WjrSbKohwiz9QbC5g+IdzHra+vtKKCpqfr7k9iT/baR5uxVuREQ6KhFu3nmn+XCzaVP40D700Fy0TqTLUrgREemoRLjZtAnefTfcPvLIML4gEW4OOaTxg0xEskLhRkSko5L3ikrsldS7d9jr4513QrdUV9hTSKST6fSdoYlw08zxxkREcitxniUIu1RXVIRBlYljnnTk/FAictA6f7hZMp8buR7fviPXTRHJK92jvWdWr17Nueee2+w8U6ZMYf78+dlsVry8807jXlBvvbX/+XtWrAh7UynciGRdpw83BYsWcj3fx7ZtzXVTRPLSIYccwuzZs3PdjM6vujrs4p2wZ084x84JJzQeoC353EDbt4fz8CjciGRdpw83iX6pvTs16EakNddddx233Xbbvvs33HADN910E6eccgrjxo3juOOO47FmDrxVVVXFscceC8CuXbs4//zzGTlyJJ/5zGd0bqlk3/kOnHlm4/3q6sYzGU+YEKYddVS4HjcuXJs17j0lIlnT6QcUU1ICQMMuhRuJiRkzGg9pny5jxrR5Rs5p06YxY8YMrrjiCgAeeughnnnmGa666ip69uzJhg0bmDRpEmeddRbWwjEl7rjjDioqKli2bBmLFy9mXOJLWkI309q14aBo3bvvf06m558Pg4cTBzA75ZRw36x9B7wTkbRoM9yYWRkwDyiN5p/t7t9tMk8pcC8wHtgITHP3qrS0MKrcNNTuScviRPLV2LFjWb9+PatXr6ampoY+ffowePBgrrnmGubNm0dBQQGrVq1i3bp1DB48uNllzJs3j6uiw8ePHj2a0akeZr8rSD4J4KhR+4eb4uIDz3rd1lF/RSRjUqnc7AZOdvcdZlYMvGhmT7t78mmFLwE2u/sRZnY+cAswLS0tjMKN16pyIzHRRoUlk8477zxmz57N2rVrmTZtGrNmzaKmpoYFCxZQXFxMZWUltdr1sP0S42sgDCJOhJuCgnCIexHpVNocc+NBYlel4ujS9EQZU4F7otuzgVOspbp3eynciKRs2rRpPPDAA8yePZvzzjuPrVu3MnDgQIqLi5kzZw4rV65s9fknnXTSvpNvLl26lMWLF2ej2Z3fu+82nh8o+ZQLw4aFqo2IdCopDSg2s0IzWwSsB55z91ebzDIUeA/A3euBrUC/tLRQR/ETSdmoUaPYvn07Q4cOZciQIXz+859n/vz5HHfccdx7770cffTRrT7/8ssvZ8eOHYwcOZLrr7+e8ePHZ6nlnVzywfqST7mgPaFEOqWUBhS7+15gjJn1Bh41s2PdfWl7V2ZmlwGXARya6rlWFG5E2mXJkiX7bvfv35+XX3652fl27AgF2crKSpYuDf/O5eXlPPDAA5lvZNwkAk337iHUJKadckquWiQirWjXruDuvgWYA5zW5KFVwHAAMysCehEGFjd9/kx3n+DuEwYMGJDaSqO9pRRuRCRnqqrC2YwnTQq3E2NwVLkR6ZTaDDdmNiCq2GBm5cDHgX80me1xYHp0+1zgz+7edFxOxyQqN3u0t5SI5EhVFQwfHk6KuXw5fO97YQyOwo1Ip5RK5WYIMMfMFgN/I4y5edLMvmdmZ0Xz3AX0M7MVwFeB69LWwijc2B5VbqRzS1ee7+y6ynbup7o6DB6eODEcefjmm8NA4rFjc90yEWlGm2Nu3H0xcMB/sLtfn3S7FjgvvU2LKNxIDJSVlbFx40b69evX4gHy8oG7s3HjRsrKynLdlOzasgUOOwymT4fzzgtHJi4qgq72OojEROc/QnEUbgrqFG6k8xo2bBjV1dXU1NTkuikZV1ZWxrCudmyXLVvg+OPD7YqK3LZFRNqkcCOSBsXFxYwYMSLXzZBM2bJFRxwWiZHOf+LMaG+pgnoNKBaRHGhogG3bFG5EYiQ24aawXpUbEcmBbdvCnlEKNyKx0fnDjRn1hSUKNyKSG1u2hGuFG5HY6PzhBqgvLKVo72664h6oIpJjCjcisROLcLO3qJQSdlNfn+uWiEg2mdk1Zva6mS01s/vNrMzMRpjZq2a2wsweNLOSjDZC4UYkdmIRbhqKSyllN7W1uW6JiGSLmQ0FrgImuPuxQCFwPnAL8BN3PwLYDFyS0YYo3IjETjzCTVEJJezR6aVEup4ioDw6Z10FsAY4GZgdPX4PcHZGW6BwIxI78Qg3UeVG4Uak63D3VcB/Ae8SQs1WYAGwxd0TndTVwNDmnm9ml5nZfDObf1AHV1S4EYmdWIQbV7gR6XLMrA8wFRgBHAJ0A05L9fnuPtPdJ7j7hAEDBnS8IYlw07Nnx5chIlkVj3BTonAj0gWdCrzj7jXuXgc8AkwGekfdVADDgFUZbcWWLSHYFBZmdDUikj7xCDelCjciXdC7wCQzq7BwNtJTgDeAOcC50TzTgccy2gqdekEkdmIRblDlRqTLcfdXCQOHFwJLCJ9XM4F/B75qZiuAfsBdGW2Iwo1I7HT+E2cClJRQwmZq63LdEBHJJnf/LvDdJpPfBk7MWiMUbkRiJxaVm0S3VJ3CjYhk0+zZsHy5wo1IzMSkcqNwIyI58LnPQX09jB2b65aISDvEonJDVLnR6RdEJGv27g3B5vrr4YYbct0aEWmHeISbMlVuRCTLEr+mSktz2w4RabdYhBsrU+VGRLIs8WuquDi37RCRdotHuCkJ55ZS5UZEsibxa6ooHkMTRaRRPMJNubqlRCTLVLkRia14hJuyUorYy949e3PdFBHpKlS5EYmtNsONmQ03szlm9oaZvW5mVzczzxQz22pmi6LL9WltZFkY0Ld3lw5RLCJZosqNSGyl8pOkHrjW3ReaWQ9ggZk95+5vNJnvf9390+lvIhSUR3sr1O4GKjKxChGR/SnciMRWm5Ubd1/j7guj29uBZcDQTDcsWUFZCQANqtyISLaoW0oktto15sbMKoGxwKvNPPwhM3vNzJ42s1EtPP8yM5tvZvNrampSXm9hRajcNNTuaU9zRUQ6TpUbkdhKOdyYWXfgYWCGu29r8vBC4DB3Px74OfD75pbh7jPdfYK7TxgwYEDqjUx0S+m04CKSLarciMRWSuHGzIoJwWaWuz/S9HF33+buO6LbTwHFZtY/XY1MVG68VuFGRLJElRuR2EplbykD7gKWufuPW5hncDQfZnZitNyNaWukKjcikm2JcKPKjUjspPJfOxn4IrDEzBZF074JHArg7r8EzgUuN7N6YBdwvrt7uhppZQo3IpJliW4pVW5EYqfNcOPuLwLWxjy/AH6RrkYdoCTsLeW7NaBYRLJE3VIisRWLIxQnwo3VKdyISJZoQLFIbMUq3LBH4UZEskSVG5HYike4KY3G3CjciEi2qHIjElvxCDfqlhKRbFPlRiS2YhVuVLkRkaxRuBGJrViFm4I67QouIlmibimR2IpVuFG3lIhkjSo3IrEVq3BTUK9wIyJZosqNSGzFI9xEe0uZwo2IZIsqNyKxFY9ws2/MjcKNiGSJwo1IbMUj3BQWspcCCvYq3IhIlqhbSiS24hFugPqCEgrrtbeUiGSJKjcisRWzcKPKjYhkiSo3IrEVn3BjJRSqW0pEsqWuDsygsDDXLRGRdopNuKkrLNWYGxHJnvp6dUmJxFRsws3eghKKFG5EJFvq6tQlJRJTsQk39YUlFDYo3IhIltTVqXIjElOxCTd7C1W5EZEsqq9X5UYkpuIVbhq0K7iIZIkqNyKxFZtw01BYQpG6pUQkW1S5EYmt2ISbvUWlFCvciEi2qHIjElsxCjclFLnCjUhXYma9zWy2mf3DzJaZ2YfMrK+ZPWdmy6PrPhlZucKNSGzFJtx4UQnFCjciXc3PgD+6+9HA8cAy4DrgeXc/Eng+up9+6pYSia02w42ZDTezOWb2hpm9bmZXNzOPmdmtZrbCzBab2bh0N7RB4UakSzGzXsBJwF0A7r7H3bcAU4F7otnuAc7OSANUuRGJrVQqN/XAte5+DDAJuMLMjmkyz6eAI6PLZcAdaW0lIdyUuPaWEulCRgA1wG/M7O9mdqeZdQMGufuaaJ61wKDmnmxml5nZfDObX1NT0/61q3IjEltthht3X+PuC6Pb2wll4aFNZpsK3OvBK0BvMxuSzoY2FJdQwh4aGtK5VBHpxIqAccAd7j4WeJ8mXVDu7oA392R3n+nuE9x9woABA9q/dlVuRGKrXWNuzKwSGAu82uShocB7SferOTAAHdQvKS8upYQ91NW162kiEl/VQLW7Jz5vZhPCzrrEj6foen1G1q5zS4nEVsrhxsy6Aw8DM9x9W0dWdjC/pLwkVG7q6zuyZhGJG3dfC7xnZkdFk04B3gAeB6ZH06YDj2WkATq3lEhspfSfa2bFhGAzy90faWaWVcDwpPvDomlp41G3lCo3Il3KV4BZZlYCvA1cTPhR9pCZXQKsBD6bkTXX1UFFRUYWLSKZ1Wa4MTMj7K2wzN1/3MJsjwNXmtkDwERga9KAv/SIws12hRuRLsPdFwETmnnolIyvXAOKRWIrlf/cycAXgSVmtiia9k3gUAB3/yXwFHA6sALYSfh1lVZeUkIZu9lc54Cle/EiIvvTgGKR2Goz3Lj7i7SRJqI9Fq5IV6OaYyUlANTtqgf0gSMiGaYBxSKxFZsjFBOFm727dCA/EckCDSgWia34hJvSUgDqdyrciEgWqFtKJLZiFG5C5UbhRkSyQgOKRWIrNuEmMeamoVbhRkSyQJUbkdiKT7iJKjd7d+r8UiKSBarciMRWbMJNQZkqNyKSRarciMRWbMLNvsqN9pYSkWzQruAisRWfcFMe9pZS5UZEskK7govEVmzCTUGpuqVEJEvc1S0lEmPxCTcacyMi2dLQEK5VuRGJpdiEm8LyEG68VntLiUiG1UVn6FXlRiSWYhNuEpUb363KjYhkWH19uFa4EYml2ISbROWmQeFGRDItUblRt5RILMUn3FSEvaVQt5SIZJq6pURiLT7hpltZuFFbm9uGiEj+S3RLqXIjEkuxCTdF3UO4sd0KNyKSYXui7u/onHYiEi+xCTcF3coBhRsRyYJEhbi8PLftEJEOiU24Ke4RdUsp3IhIpiXCTVlZbtshIh0Sm3BTVFZEPYUUKNyISKYp3IjEWmzCTXEx1FJGwe5duW6KiOQ7hRuRWItfuNmjyo2IZJjCjUisxSbcFBNicH4AABuXSURBVBQo3IhIlijciMRabMINQC3lFNQp3IhIhinciMRam+HGzO42s/VmtrSFx6eY2VYzWxRdrk9/M4PdVkahwo2IZJrCjUispXL4zd8CvwDubWWe/3X3T6elRa3YXVBGqcKNiGSawo1IrLVZuXH3ecCmLLSlTXusjKI67S0lIhmmcCMSa+kac/MhM3vNzJ42s1EtzWRml5nZfDObX1NT0+6V7C4oo0iVGxHJNIUbkVhLR7hZCBzm7scDPwd+39KM7j7T3Se4+4QBAwa0e0V7Csopqle4EZEM2xVViEtLc9sOEemQgw437r7N3XdEt58Cis2s/0G3rBl7Csso2qtwIyIZVlsbgo1ZrlsiIh1w0OHGzAabhU8AMzsxWubGg11uc+oKylS5EZHMq61Vl5RIjLW5t5SZ3Q9MAfqbWTXwXaAYwN1/CZwLXG5m9cAu4Hx390w0tq6ojOJdCjcikmEKNyKx1ma4cffPtfH4Lwi7imdcXWEZJXu1t5SIZJjCjUisxeoIxXVF5RRrzI2IZJrCjUisxSrc1BeWUdpQC5np9RIRCRRuRGItXuGmOPqw2bMntw0RkfymcCMSa7EKN3uLog+bWnVNiXQVZlZoZn83syej+yPM7FUzW2FmD5pZSdpXWlsL5eVpX6yIZEe8wk2icrNLg4pFupCrgWVJ928BfuLuRwCbgUvSvkZVbkRiLVbhpr44+iWlyo1Il2Bmw4AzgDuj+wacDMyOZrkHODvtK1a4EYm1WIWbfZUbhRuRruKnwP8PNET3+wFb3L0+ul8NDG3uiQd1LjuFG5FYi1W4aShRuBHpKszs08B6d1/Qkecf1LnsFG5EYq3Ng/h1Jgo3Il3KZOAsMzsdKAN6Aj8DeptZUVS9GQasSvuaFW5EYk2VGxHplNz9G+4+zN0rgfOBP7v754E5hNO+AEwHHkv7yhVuRGItXuGmNBpQrL2lRLqyfwe+amYrCGNw7kr7GhRuRGItVt1SXqrKjUhX5O5zgbnR7beBEzO2soaGcKBQhRuR2IpV5UbhRkQybvfucK1wIxJbsQo3+z5sFG5EJFMSny8KNyKxFatwo8qNiGRcYkyfwo1IbMUq3Ow714sGFItIpqhyIxJ7sQo3XhbCje94P8ctEZG8pXAjEnuxCjeFZcVspje+vp2HUhcRSZXCjUjsxSrcFBfDWgbjq9fkuikikq8UbkRiL1bhpqgoCjdr1+a6KSKSr3buDNeJMX4iEjuxCjeJyo2tU7gRkQxJhJtu3XLbDhHpsFiFm6IiWMMQhRsRyZz3ox0WFG5EYqvNcGNmd5vZejNb2sLjZma3mtkKM1tsZuPS38wgUbkpeH8H7NiRqdWISFeWCDcVFblth4h0WCqVm98Cp7Xy+KeAI6PLZcAdB9+s5iXCDQAadyMimaBuKZHYazPcuPs8YFMrs0wF7vXgFaC3mQ1JVwOTJQYUAwo3IpIZ6pYSib10jLkZCryXdL86mpZ2xcVhzA0Aa7Q7uIhkwPvvgxmUlua6JSLSQVkdUGxml5nZfDObX1PT/gPxqXIjIhm3c2eo2pjluiUi0kHpCDergOFJ94dF0w7g7jPdfYK7TxgwYEC7V1RcDBvphxcWKdyISGa8/766pERiLh3h5nHgwmivqUnAVnfPSJ9RcTE4BdT1GQDr1mViFSLS1b3/vvaUEom5orZmMLP7gSlAfzOrBr4LFAO4+y+Bp4DTgRXATuDijDU2am19996UbNmSqdWISFeW6JYSkdhqM9y4++faeNyBK9LWolYUF4fruopesHVrNlYpIl2NuqVEYi92RygGhRsRySCFG5HYi1W42Ve5KVe4EZEM0ZgbkdiLZbjZU9Fb4UZEMkNjbkRiL1bhJtEttbssqXKzaBHckbEzPohIV6NuKZHYa3NAcWeSqNzUlvWC2lpYvBjGjg0TL7kESkpy1zgRyQ/qlhKJvXhWbkp7hRtf/3rjgxs2ZL9BIpJ/1C0lEnuxCjeJys2uRLh57bXGB3VQPxE5WPX1sGePwo1IzMUy3NSWROFm3To47LBwe/363DRKRPJH4ozg6pYSibVYhZtEt9TOkt6NExNjblS5EZGDtXNnuFblRiTWYhVuEpWbncW9Gicmwo0qNyJysBKVG4UbkViLVbjZV7lJDjdHHQVlZarciMjBU7eUSF6IVbhJVG52FCaFm6FDYeBAVW5E5OCpW0okL8Qq3CQOY7OjoGfjxEMOgUGDVLkRkYOnbimRvBCrcFNUFC47dxdC9+5h4pAhqtyISHoo3IjkhViFG4Dycti1C+jdG/r2DRNUuRGRdNCYG5G8EN9w06tX6JKCULlZvRomT4ZVq3LaPhGJsSFD4Oyzww8nEYmt+IabD34QRo8OExMfRH/5CzzzTM7aJiIx97GPwaOPhh9MIhJbsQs3ZWVRuHngAfjNb8LEs86CL30JevaE+fNz2j4RERHJrVidFRySKjfJZwA/6ii46y6oqlK4ERER6eJiV7kpL4fa2hYenDAhnExzz56stklE0s/MhpvZHDN7w8xeN7Oro+l9zew5M1seXffJdVtFpHOJZbjZtauFBydMCMFmyZKstklEMqIeuNbdjwEmAVeY2THAdcDz7n4k8Hx0X0Rkn/wKNxMnhuunn85ae0QkM9x9jbsvjG5vB5YBQ4GpwD3RbPcAZ+emhSLSWeVXuDn0UDj1VPjVr6C+PqvtEpHMMbNKYCzwKjDI3ddED60FBrXwnMvMbL6Zza+pqclKO0Wkc0gp3JjZaWb2ppmtMLMDSsBmdpGZ1ZjZoujyb+lvatBquAG48kqorobHHstUE0Qki8ysO/AwMMPdtyU/5u4OeHPPc/eZ7j7B3ScMGDAgCy0Vkc6izXBjZoXAbcCngGOAz0X93k096O5josudaW7nPm2Gm09/Go44Ar7/fWhoyFQzRCQLzKyYEGxmufsj0eR1ZjYkenwIoHOviMh+UqncnAiscPe33X0P8AChzzsn2gw3hYVwww1hr6l7781Ws0QkzczMgLuAZe7+46SHHgemR7enAyrTish+Ugk3Q4H3ku5XR9OaOsfMFpvZbDMb3tyC0tEH3ma4ATj/fDjxRLj4YvjhDxunr10LP/857NzZoXWLSFZNBr4InJzU5X068APg42a2HDg1ui8isk+6DuL3BHC/u+82s/9D2IPh5KYzuftMYCbAhAkTmu0nb0t5OdTVwd69oUjTrMJCmDMHPv95+Pa3QzfV738PTzwBW7aEkHPzzR1ZvYhkibu/CFgLD5+SzbaISLykEm5WAcmVmGHRtH3cfWPS3TuBH5Ih5eXhetcu6N69lRkrKkKV5umn4ZxzwvmnTj01HAHwRz+Ck08OlxUrwjxbt4bzVf3rv8Irr8BvfxuqPxddBKWlmdocERERSbNUws3fgCPNbAQh1JwPXJA8g5kNSdo18yzC8SgyIhFuamvbCDcAw4bBf/wHzJ0bTs8wYEA4a/jEiSHo/Mu/hNM1vP/+/ivYtSucxOruu2HRIrjjjpbXsWZNWG5REezYAf/8Jxx+OPTo0fJzGhpC11j37uE5bW6IiIiIpKrNMTfuXg9cCTxDCC0PufvrZvY9Mzsrmu2q6PDorwFXARdlqsFlZeG6zXE3CV/9Kjz+eAggAEOHwvLl8JOfwMKFcPTRIZDs3h3OBnzBBSEIbdwIX/4y/PrX8PDDoYJz5pnw5JPwrW/B5s1huYcdBmecEbq9Ro6EMWPCGYVnzAjBJ+GRR+BDHwrH4hk0CHr3hlGjwsk+f/e7jr8g27a1fboJ97B7vATu+bUn3apV8LOfwf/9v/DjH4fjPKX8DyIikn8sHCYi+yZMmODzO3CSy1mz4AtfgDffDL1IB2X79lCpKWqhgLV+PXzgA6G6UlYGZo1fGn37wqZNoUrz9tth2gc/CN/8JrzwQthTq6QE/vAHeO89mD49hJ/x46GgAPr3h7/9Laxj40a4/3445JAQmmpr4cgjQ9ueeCIsd/16eOqpxsHSzz0Ht98Of/5zmO+118JzmqqtDcf+uesuOOkkuOceqKwMX/A33xxCz7//e9iukSNDePvKV2DqVPjYx+C448Jr0FRDA2zYEEKjtTQsog2bNoXK2Jgx4fXMlIaG8LrW1cF998Gtt0K/fiEQNDTAhz8c/hZeeSW81vX14TUdPjxU2Favbv617ai6OiguPnD60qXwxhvwyU9Cr16pLWv79vD+NB2gX14OffqE93j69I6/R+1gZgvcfULGV9QBHf28EZHOq9XPHHfPyWX8+PHeEQ8/7A7uixZ16Ontt2iR+1NPua9b575kifutt7o/84z7pz7lfuON7tu2uT/wQLjs2dP4vBUr3I86yr1Hj9Dgk09237XrwOUvXerevXuYJ/li5t6r14HT+/VzP+KIxtvf/rZ7cbH7VVftv9z6evdvftO9oiLMe8EF7r17u3/gA+7nnOM+btyBy+7TJ1wPH944rVevsM0XXug+ZYr7bbe5P/qo++DB4fEpU9y3bGlc59tvu69a5f7SS+5f+lKYf80a971792/fSy+5l5c3ruM73wmv75//7H7ffe4NDQf/3q1a5X7RRe5lZftv5+TJje8LHPh44nLIIe4DBoTbH/6w+5w57tde637DDe4PPeR+9dXu//VfqbVlzx73lSvDH3BZmfv3v+++bJn7XXe5v/ii+5e/3Ljeigr3K690v/1291dfdb/5ZvdvfMP9r38Ny0p+bX72s/Cc5593377dfdMm97lzQ9s+/OHw2I03ur/1lvvTT7tXV4fnvfJKWG5d3f7tXLcu/H1/+cvuH/qQ+zXXuK9fn9ImAvM9R58nbV06+nkjIp1Xa585savcPP00nH46vPwyTJqUgYal05Ilofpxzjnw0582DhhqatMm+Pvfw6/vnj2hWzf44x9Deeqaa8IeXgMGhOdPnBgqQvffH8YNlZaGrrQ//AG+/nU4/ni46aZQFXKHz30OLrsMpkwJL9onPhGqJIcdFg54+LGPwbx5YdkvvRTGIU2fHqoIGzaE5777bqg0DRgAy6LhVEcfHbbrBz8Iu6717Rv2UkuuIJSWhu4+CBWgm28OXXUvvRQqTxUVoRvlrrtChSr5b/Gqq+CWW8IyV6wIr8WRR4auvFT87W9w9tmhYvOFL8Axx4Tlf/Sj4QSrK1aEeYqKQnsGDgwVsbfeCq//+++HPe727IHJk+E//zO8HkVFYXuT2/qjH4UKWP/+YQ+9ww4L0+vrQ7fm22+HCtvChaGC0qtXeE+buvJKOO+88HrMmhXWk1BUFJY3cmToRv3wh0P36GWXweDB8Je/HLi8vXvhS1/a/3hPvXrBpz4FDz0UqlZf/GLYxj17QrfpLbeESmJxcagyLl0a3rMUxoWpciMi2dTaZ07sws3cueH7+M9/DtedXkND6IZKl7/8JYzXOSbpINGvvhq+mBLvZffuYbzQiSeGAJKstjaEjlS7KbZtC+HmmGPCc15/HRYvDuOMevUKwWDuXFi5MnThfPSjoR09eoTw9Pe/h8stt8C6dWGZgwaFbqFZs0KXFEBVFbz4Yghuf/lL6DLq3Tt0CSafJ+zyy0N3XFObN8N3vhPCVJ8+YU+5QYPCuKjRo1Pb1tasWhXWe9FFoftw2bLGPfDeeacxyBUWhj3tSkrCwSSXLQtBoUcPuOKKEHR+9KPQdbl7d2jb//xPeG1vuaXxfdm1KwTFF16AY48NXU/f+14YAD96dBintXZtWO+TT4Z2NKeuLgyqHzgwHBLhq18N7b300tCllRho3717mH7ooXDnnSGMDh7cchdaMxRuRCSb8ircvPpqqNj84Q+hgiORNWvCF92jj4YXKNUKR7Zs3RrGBfXpE76s2wpXf/pTqDgMHRqC1Qc/GPZemzkzPHbKKWF8yvXXh8rMjBkhgCT2djv11DC+aODAzG7X0qWwYEEYC7V+faiEvPBCeGzkyBAszjgj3E8xJKRk/foQti64oH2Dz+rqwqWiIlRr/vSn8CuhrCyEyyOPDKGmAxRuRCSb8ircLF4cel5mzz6wKCF5rrY2BKO9e8MeQRdfHAb7QqiiPP00jB0bKkclJblp47Zt8I1vwEc+Ap/9bCtHmsw/Cjcikk2tfeak6wjFWZN8ED/pYsrKQlfWKaeEPYoGDoRnnw1dNJdfHoJNrvXsCbfdlutWiIh0aQo3Ei8TJ8Izz4RxJl//eqjYfPzjuW6ViIh0IrENN7W1uW2H5NDkyeEiIiLSjDTuxpMdqtyIiIhIa2IXbtp9+gURERHpUmIXbgoKwo4wCjciIiLSnNiFG2g8lImIiIhIU7EMN926hQPXioiIiDQVy3AzfHg4I4CIiIhIU7HbFRxgxAj4619z3QoRibO6ujqqq6up7QLHlSgrK2PYsGEUp/MUICKdWGzDzezZ4Sj8Xejo9iKSRtXV1fTo0YPKykos1RPJxpC7s3HjRqqrqxkxYkSumyOSFbHsljr88HCi6OrqXLdEROKqtraWfv365XWwATAz+vXr1yUqVCIJsQw3iR8fb7+d23aISLzle7BJ6CrbKZIQy3Bz+OHh+p13ctsOERER6XxiGW6GDw9jbRRuRKQr6d69OwCrV6/m3HPPbXaeKVOmMH/+/Gw2S6TTiWW4KSoKAUfdUiLSFR1yyCHMnj07180Q6bRiubcUwPHHw9y5UFcH2rtRRA7KjBmwaFF6lzlmDPz0p63Oct111zF8+HCuuOIKAG644QaKioqYM2cOmzdvpq6ujptuuompU6fu97yqqio+/elPs3TpUnbt2sXFF1/Ma6+9xtFHH80uHb5dJJ6VG4AvfQlWr4YnnoAFC+CKK3TUYhGJl2nTpvHQQw/tu//QQw8xffp0Hn30URYuXMicOXO49tprcfcWl3HHHXdQUVHBsmXLuPHGG1mwYEE2mi7SqaVUuTGz04CfAYXAne7+gyaPlwL3AuOBjcA0d69Kb1P3d8YZoWvqm9+ETZugpibsHv6rX2VyrSKSl9qosGTK2LFjWb9+PatXr6ampoY+ffowePBgrrnmGubNm0dBQQGrVq1i3bp1DB48uNllzJs3j6uuugqA0aNHM3r06Gxugkin1GblxswKgduATwHHAJ8zs2OazHYJsNndjwB+AtyS7oY2VVgIt94Ke/aAGXzxizBzJtxySzi4n4hIHJx33nnMnj2bBx98kGnTpjFr1ixqampYsGABixYtYtCgQTpGjUg7pVK5ORFY4e5vA5jZA8BU4I2keaYCN0S3ZwO/MDPz1mqpaXD22TB1aggzDQ1h/M1118FNN8HAgVBWFs4gnrguLYWCgv0vZgfeb3oJ2936tGTJ91t7rL3zdjadvX2gNqbD978PPXrkuhX5a9q0aVx66aVs2LCBF154gYceeoiBAwdSXFzMnDlzWLlyZavPP+mkk7jvvvs4+eSTWbp0KYsXL85Sy0U6r1TCzVDgvaT71cDEluZx93oz2wr0AzYkz2RmlwGXARx66KEdbPL+zMLeUwCzZoXA89JLsHkz7NoFtbXh+v33Q/dVQwO4h+vkS/I098ZL2KbWpyVLvt/aY+2dt7Pp7O0DtTFdvvUthZtMGjVqFNu3b2fo0KEMGTKEz3/+85x55pkcd9xxTJgwgaOPPrrV519++eVcfPHFjBw5kpEjRzJ+/PgstVyk88rq3lLuPhOYCTBhwoS0f6wXFMC0aeEiIhIXS5Ys2Xe7f//+vPzyy83OtyPaa6KyspKlS5cCUF5ezgMPPJD5RorESCp7S60ChifdHxZNa3YeMysCehEGFouIiIhkVSrh5m/AkWY2wsxKgPOBx5vM8zgwPbp9LvDnTI+3EREREWlOm91S0RiaK4FnCLuC3+3ur5vZ94D57v44cBfw32a2AthECEAiIp2au3eJk0rqt6Z0NSmNuXH3p4Cnmky7Pul2LXBeepsmIpI5ZWVlbNy4kX79+uV1wHF3Nm7cSFlZWa6bIpI1sT39gojIwRg2bBjV1dXU1NTkuikZV1ZWxrBhw3LdDJGsUbgRkS6puLiYESNG5LoZIpIBsT23lIh0bWZ2mpm9aWYrzOy6XLdHRDoPhRsRiZ0UTwsjIl2Uwo2IxNG+08K4+x4gcVoYEZHcjblZsGDBBjNr/aQpjfrT5FQOeSjft1HbF39tbeNh2WoIKZwWJvl0L8AOM3szxWXrvYw/bV/8pbKNLX7m5CzcuPuAVOc1s/nuPiGT7cm1fN9GbV/8xW0bk0/30h5x286OyPdt1PbF38Fuo7qlRCSOUjktjIh0UQo3IhJHqZwWRkS6qLgc56bdpeUYyvdt1PbFX6fZxpZOC5OmxXea7cygfN9GbV/8HdQ2ms45IiIiIvlE3VIiIiKSVxRuREREJK90+nCTj4dYN7MqM1tiZovMbH40ra+ZPWdmy6PrPrluZ3uY2d1mtt7MliZNa3abLLg1ek8Xm9m43LU8NS1s3w1mtip6HxeZ2elJj30j2r43zeyTuWl16sxsuJnNMbM3zOx1M7s6mp4372Eq9HkTD/q80edNmytx9057IQwU/CdwOFACvAYck+t2pWG7qoD+Tab9ELguun0dcEuu29nObToJGAcsbWubgNOBpwEDJgGv5rr9Hdy+G4CvNTPvMdHfaikwIvobLsz1NrSxfUOAcdHtHsBb0XbkzXuYwmugz5uYXPR5s9+8+rxp5tLZKzdd6RDrU4F7otv3AGfnsC3t5u7zgE1NJre0TVOBez14BehtZkOy09KOaWH7WjIVeMDdd7v7O8AKwt9yp+Xua9x9YXR7O7CMcBTgvHkPU6DPm5jQ581+9HnTjM4ebpo7xPrQHLUlnRx41swWWDhEPMAgd18T3V4LDMpN09KqpW3Kp/f1yqhMendSaT/W22dmlcBY4FW6xnuYkI/bBPq8yaf3VZ83QZvb2NnDTb76iLuPI5zR+AozOyn5QQ91uLzaRz8ftwm4A/gAMAZYA/wot805eGbWHXgYmOHu25Ify9P3sCvQ501+0OdNO3T2cJOXh1h391XR9XrgUUIJcV2izBZdr89dC9OmpW3Ki/fV3de5+153bwB+TWMpOJbbZ2bFhA+aWe7+SDQ5r9/DJvJxm/R5kyfvqz5v2reNnT3c5N0h1s2sm5n1SNwGPgEsJWzX9Gi26cBjuWlhWrW0TY8DF0Yj4CcBW5NKkbHRpM/3M4T3EcL2nW9mpWY2AjgS+Gu229ceZmbAXcAyd/9x0kN5/R42oc+beMvrv1V93rTzPcz1qOm2LoRR0m8RRoB/K9ftScP2HE4Y2f4a8Hpim4B+wPPAcuBPQN9ct7Wd23U/oVRaR+gPvaSlbSKMeL8tek+XABNy3f4Obt9/R+1fHP3zDUma/1vR9r0JfCrX7U9h+z5CKAEvBhZFl9Pz6T1M8XXQ500MLvq80edNW+vQ6RdEREQkr3T2bikRERGRdlG4ERERkbyicCMiIiJ5ReFGRERE8orCjYiIiOQVhRsRERHJKwo3IiIiklf+H4qX01x0FYFSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo_CN5XKjSxU"
      },
      "source": [
        "# [라벨링 순서]\n",
        "\n",
        "# '1'     , '2'     , '3'     , '4'     , '5'     , '6'     , '7'     , '8'     , '9'     , '10'    , '11'    , '12'    ,'13'    , '14'    , '15'    , '16'    , '17'    , '18'    , '19'    , '20'    '21'    , '22',   '23',   '24', '25',  '26'\n",
        "# '박경원', '김동현', '이수연',    '정재원',  '박성환',  '심형준',   '유지현',   '장종빈',  '임현우',   '안제호',   '박세진',  '이민구', '김장현',  '류승현',  '고무현',   '심대한',   '김영민',   '정성현',  '임태윤',  '진형민',   '김동원',   '변준', '박찬진', '차재빈', '허준영','신승민(조교)'\n",
        "\n",
        "\n",
        "Confusion matrix를 그려봅니다. (Training & Validation)\n",
        "\n",
        "Confusion matrix는 실제 정답과 예측한 정답 사이의 관계를 나타낸 표입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwgB_5t-jVvP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "b5b50bcc-af40-4b11-837d-93c5fff57639"
      },
      "source": [
        "# '1'     , '2'     , '3'     , '4'     , '5'     , '6'     , '7'     , '8'     , '9'     , '10'    , '11'    , '12'    , '13'    , '14'    , '15'    , '16'    , '17'    , '18'    , '19'    , '20'    , '21'    , '22'     \n",
        "# '박경원', '김동현', '이수연', '정재원', '박성환', '심형준', '유지현', '장종빈', '임현우', '안제호', '박세진', '이민구', '김장현', '류승현', '고무현', '심대한', '김영민', '정성현', '임태윤', '진형민', '김동원', '변준(조교)'\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Check point Settings\n",
        "CHECK_POINT_PATH = str('./Spk_Recog_6.30_SPK_RECOG_MODEL_Categorical_CE/chkpt_199.pt')\n",
        "checkpoint = torch.load(CHECK_POINT_PATH)\n",
        "\n",
        "\n",
        "# Model Load\n",
        "model = SPK_RECOG_MODEL().to(DEVICE)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "model.eval()\n",
        "\n",
        "# Load data (Validation data)\n",
        "print('Load data...')\n",
        "X_valid = pickle.load(open('./data/mfcc_features_devel', 'rb'))\n",
        "Y_valid = pickle.load(open('./data/labels_devel', 'rb'))\n",
        "\n",
        "\n",
        "X_valid = np.transpose(X_valid, (0, 2, 1))\n",
        "X_valid = torch.from_numpy(X_valid).float().to(DEVICE)\n",
        "\n",
        "\n",
        "y_pred = model(X_valid).to('cpu').detach().numpy()\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_gt = Y_valid.squeeze(1)\n",
        "\n",
        "# '1'     , '2'     , '3'     , '4'     , '5'     , '6'     , '7'     , '8'     , '9'     , '10'    , '11'    , '12'    ,\n",
        "# '박경원', '김동현', '이수연',    '정재원',  '박성환',  '심형준',   '유지현',   '장종빈',  '임현우',   '안제호',   '박세진',  '이민구',\n",
        "# '13'    , '14'    , '15'    , '16'    , '17'    , '18'    , '19'    , '20'    , '21'    , '22',   '23',   '24',   '25',   '26'\n",
        "#'김장현',  '류승현',  '고무현',   '심대한',   '김영민',   '정성현',  '임태윤',  '진형민',   '김동원',   '변준', '박찬진', '차재빈', '허준영','신승민(조교)'\n",
        "plt.figure(figsize=(8, 8))\n",
        "cm2 = confusion_matrix(y_gt, y_pred, labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21, 22, 23, 24, 25, 26])\n",
        "plt.imshow(cm2, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix (Validation set)\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(26)\n",
        "plt.xticks(tick_marks, ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26'], rotation=45)\n",
        "plt.yticks(tick_marks, ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26'])\n",
        "thresh2 = cm2.max()/2.\n",
        "normalize = False\n",
        "fmt = '.2f' if normalize else 'd'\n",
        "for i, j in itertools.product(range(cm2.shape[0]), range(cm2.shape[1])):\n",
        "  plt.text(j, i, format(cm2[i,j], fmt), horizontalalignment=\"center\", color=\"white\" if cm2[i, j] > thresh2 else \"black\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
